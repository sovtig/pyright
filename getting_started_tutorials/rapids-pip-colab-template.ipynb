{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/rapids-pip-colab-template.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Install RAPIDS into Colab\"/>\n",
        "</a>\n",
        "\n",
        "# RAPIDS cuDF is now already on your Colab instance!\n",
        "RAPIDS cuDF is preinstalled on Google Colab and instantly accelerates Pandas with zero code changes. [You can quickly get started with our tutorial notebook](https://nvda.ws/rapids-cudf). This notebook template is for users who want to utilize the full suite of the RAPIDS libraries for their workflows on Colab.  \n",
        "\n",
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "You can check the output of `!nvidia-smi` to check which GPU you have.  Please uncomment the cell below if you'd like to do that.  Currently, RAPIDS runs on all available Colab GPU instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67T0090Jk2KL"
      },
      "source": [
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_v33LnDVNo3"
      },
      "source": [
        "#Setup:\n",
        "This set up script:\n",
        "\n",
        "1. Checks to make sure that the GPU is RAPIDS compatible\n",
        "1. Pip Installs the RAPIDS' libraries, which are:\n",
        "  1. cuDF\n",
        "  1. cuML\n",
        "  1. cuGraph\n",
        "  1. cuSpatial\n",
        "  1. cuxFilter\n",
        "  1. cuCIM\n",
        "  1. xgboost\n",
        "\n",
        "# Controlling Which RAPIDS Version is Installed\n",
        "This line in the cell below, `!python rapidsai-csp-utils/colab/pip-install.py`, kicks off the RAPIDS installation script.  You can control the RAPIDS version installed by adding either `latest`, `nightlies` or the default/blank option.  Example:\n",
        "\n",
        "`!python rapidsai-csp-utils/colab/pip-install.py <option>`\n",
        "\n",
        "You can now tell the script to install:\n",
        "1. **RAPIDS + Colab Default Version**, by leaving the install script option blank (or giving an invalid option), adds the rest of the RAPIDS libraries to the RAPIDS cuDF library preinstalled on Colab.  **This is the default and recommended version.**  Example: `!python rapidsai-csp-utils/colab/pip-install.py`\n",
        "1. **Latest known working RAPIDS stable version**, by using the option `latest` upgrades all RAPIDS labraries to the latest working RAPIDS stable version.  Usually early access for future RAPIDS+Colab functionality - some functionality may not work, but can be same as the default version. Example: `!python rapidsai-csp-utils/colab/pip-install.py latest`\n",
        "1. **the current nightlies version**, by using the option, `nightlies`, installs current RAPIDS nightlies version.  For RAPIDS Developer use - **not recommended/untested**.  Example: `!python rapidsai-csp-utils/colab/pip-install.py nightlies`\n",
        "\n",
        "\n",
        "**This will complete in about 5-6 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3eead9-fe6c-4563-e680-0b68cc791bd3"
      },
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 490, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 490 (delta 149), reused 124 (delta 91), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (490/490), 136.70 KiB | 6.21 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 714.5 kB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n",
            "Installing the rest of the RAPIDS 24.4.* libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (24.4.1)\n",
            "Collecting cuml-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1200.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 1.1 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1429.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 460.9 kB/s eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 MB 8.3 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 920.9/920.9 kB 61.9 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.4.1-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.5/83.5 kB 14.3 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 101.3 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.0/823.0 MB 1.7 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.1/170.1 MB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.9.5)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (5.3.3)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2023.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.58.1)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (1.25.2)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.4)\n",
            "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (14.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (13.7.1)\n",
            "Requirement already satisfied: rmm-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (4.12.2)\n",
            "Collecting dask-cuda==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.6/126.6 kB 3.7 MB/s eta 0:00:00\n",
            "Collecting dask-cudf-cu12==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.4.1-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 7.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.4.2)\n",
            "Collecting rapids-dask-dependency==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.11.4)\n",
            "Collecting treelite==4.1.2 (from cuml-cu12==24.4.*)\n",
            "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 810.9/810.9 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting pylibcugraph-cu12==24.4.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1430.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 912.3 kB/s eta 0:00:00\n",
            "Collecting ucx-py-cu12==0.37.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 104.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.4.*) (0.13.2)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (3.3.4)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading datashader-0.16.2-py2.py3-none-any.whl (18.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 53.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.17.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.3.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: scikit-image<0.23.0a0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.19.3)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 7.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Collecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 64.0 MB/s eta 0:00:00\n",
            "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 64.5 MB/s eta 0:00:00\n",
            "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.7/161.7 kB 23.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (7.2.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (9.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (2024.6.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.4.*) (3.0.10)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.4.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.1.0)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.4.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.31.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2023.7.0)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.9.6)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2.0.4)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.4.*) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.4.*) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.6)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (4.66.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (6.1.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (1.6.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.7)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.4.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.4.*) (2.16.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2024.6.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.20.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.4.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (1.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.4.*) (3.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.19.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.22)\n",
            "Installing collected packages: simpervisor, pynvml, pyct, ucx-py-cu12, treelite, dask, pylibraft-cu12, distributed, dask-expr, cuproj-cu12, cucim-cu12, rapids-dask-dependency, pylibcugraph-cu12, datashader, cuspatial-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.0\n",
            "    Uninstalling pynvml-11.5.0:\n",
            "      Successfully uninstalled pynvml-11.5.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2023.8.1\n",
            "    Uninstalling distributed-2023.8.1:\n",
            "      Successfully uninstalled distributed-2023.8.1\n",
            "Successfully installed cucim-cu12-24.4.0 cugraph-cu12-24.4.0 cuml-cu12-24.4.0 cuproj-cu12-24.4.0 cuspatial-cu12-24.4.0 cuxfilter-cu12-24.4.1 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu12-24.4.1 dask-expr-0.4.0 datashader-0.16.2 distributed-2024.1.1 jupyter-server-proxy-4.2.0 pyct-0.5.0 pylibcugraph-cu12-24.4.0 pylibraft-cu12-24.4.0 pynvml-11.4.1 raft-dask-cu12-24.4.0 rapids-dask-dependency-24.4.1 simpervisor-1.0.0 treelite-4.1.2 ucx-py-cu12-0.37.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJMJ6BulmMn"
      },
      "source": [
        "# RAPIDS is now installed on Colab.  \n",
        "You can copy your code into the cells below or use the below to validate your RAPIDS installation and version.  \n",
        "# Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLrk46BllED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc830d51-fa13-41c4-f62b-44fa085996fa"
      },
      "source": [
        "import cudf\n",
        "cudf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.04.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuml\n",
        "cuml.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xgAFgI15ddf6",
        "outputId": "9dedd5ab-d1ae-4139-979d-a8caa00ea7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.04.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cugraph\n",
        "cugraph.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JOCMWaUal1fI",
        "outputId": "a0341787-e9e4-4fd5-b454-127e92b9c46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.04.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuspatial\n",
        "cuspatial.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AnmtYjzvVTtv",
        "outputId": "cfc0e3e8-1749-472a-e529-349d78f7eb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.04.00'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuxfilter\n",
        "cuxfilter.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CYjcARDFVWWD",
        "outputId": "e385e426-e997-4811-9f18-8a9d5dd6dade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'24.04.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlsyk9m9NN2K"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-contrib"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GE3Jvj8d3_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "g8mSAzHpbQpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: This Google Apps Script function fetches data from an API, processes it, and securely saves it to Google Drive while integrating with ODrive. Here’s a concise breakdown:\n",
        "# Key Features\n",
        "# Configuration Management:\n",
        "# Uses PropertiesService to store and retrieve API_URL, API_KEY, DRIVE_FOLDER_ID, and NOTIFICATION_EMAIL.\n",
        "# Validates configuration before execution.\n",
        "# Error Handling:\n",
        "# Logs errors and sends email notifications for both success and failure.\n",
        "# Data Transformation:\n",
        "# Filters and reformats the data (e.g., multiplies values by 1.1).\n",
        "# Security:\n",
        "# Encrypts data using Utilities.base64Encode before saving.\n",
        "# ODrive Integration:\n",
        "# Saves files to a Google Drive folder synced with ODrive for cross-cloud backup.\n",
        "# Unique Filenames:\n",
        "# Generates filenames using timestamps to avoid overwriting.\n",
        "# Workflow\n",
        "# Fetch Data:\n",
        "# Retrieves data from the API with an optional Authorization header.\n",
        "# Validate Data:\n",
        "# Ensures the data is valid JSON.\n",
        "# Transform Data:\n",
        "# Applies custom logic (e.g., filtering, reformatting).\n",
        "# Encrypt Data:\n",
        "# Encodes data using base64 for security.\n",
        "# Save Data:\n",
        "# Creates a file in the specified Google Drive folder.\n",
        "# Notify:\n",
        "# Sends email notifications with the file URL or error details.\n",
        "\n",
        "import time\n",
        "\n",
        "function processAndSaveData() {\n",
        "  // Configuration\n",
        "  const API_URL = PropertiesService.getScriptProperties().getProperty('AIzaSyDrvN36Lw6NONH8v2Y_k3YNJErgprmOgP4');\n",
        "  const API_KEY = PropertiesService.getScriptProperties().getProperty('AIzaSyDrvN36Lw6NONH8v2Y_k3YNJErgprmOgP4');\n",
        "  const DRIVE_FOLDER_ID = PropertiesService.getScriptProperties().getProperty('DRIVE_FOLDER_ID');\n",
        "  const NOTIFICATION_EMAIL = PropertiesService.getScriptProperties().getProperty('NOTIFICATION_EMAIL');\n",
        "\n",
        "  if (!API_URL || !API_KEY || !DRIVE_FOLDER_ID || !NOTIFICATION_EMAIL) {\n",
        "    Logger.log('Error: Missing configuration properties.');\n",
        "    MailApp.sendEmail(NOTIFICATION_EMAIL, 'Data Processing Error', 'Missing configuration properties.');\n",
        "    return;\n",
        "  }\n",
        "\n",
        "\n",
        "  try {\n",
        "    // 1. Fetch Data\n",
        "    let url = API_URL;\n",
        "    let headers = {};\n",
        "    if (AIzaSyDrvN36Lw6NONH8v2Y_k3YNJErgprmOgP4) {\n",
        "        headers = {Authorization: 'Bearer ' + API_KEY};\n",
        "    }\n",
        "    const response = UrlFetchApp.fetch(url, {headers: headers});\n",
        "    const data = JSON.parse(response.getContentText());\n",
        "\n",
        "\n",
        "    // 2. Validate Data (Example: check if data is an array)\n",
        "    if (!Array.isArray(data)) {\n",
        "        throw new Error(\"Invalid data format: Expected an array.\");\n",
        "    }\n",
        "\n",
        "    // 3. Transform Data (Example: filter and multiply)\n",
        "    const processedData = data.filter(item => item.value > 10)\n",
        "      .map(item => ({...item, value: item.value * 1.1 }));\n",
        "\n",
        "    // 4. Encrypt Data\n",
        "    const encryptedData = Utilities.base64Encode(JSON.stringify(processedData));\n",
        "\n",
        "\n",
        "    // 5. Save Data\n",
        "    const timestamp = new Date().getTime();\n",
        "    const filename = `processed_data_${timestamp}.txt`;\n",
        "    const folder = DriveApp.getFolderById(DRIVE_FOLDER_ID);\n",
        "    const file = folder.createFile(filename, encryptedData);\n",
        "\n",
        "    // 6. Notify Success\n",
        "    const fileUrl = file.getUrl();\n",
        "    MailApp.sendEmail(NOTIFICATION_EMAIL, 'Data Processing Successful', `Data processed and saved successfully. File URL: ${fileUrl}`);\n",
        "    Logger.log(`Data processed and saved successfully. File URL: ${fileUrl}`);\n",
        "\n",
        "  } catch (error) {\n",
        "    // 6. Notify Error\n",
        "    Logger.log(`Error: ${error}`);\n",
        "    MailApp.sendEmail(NOTIFICATION_EMAIL, 'Data Processing Error', `An error occurred: ${error}`);\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "lhoWTJ59bT3N",
        "outputId": "375643cf-64ef-4838-95d1-7953e3d5d9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-26-54d45a4870d8>, line 32)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-54d45a4870d8>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    function processAndSaveData() {\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "google drive folder link to share\n",
        "email sovtig@gmail.com"
      ],
      "metadata": {
        "id": "oXkuzP1w5K0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you for the detailed feedback and suggestions! Here's an enhanced version of the collectData() function that incorporates your recommendations for configuration options, error reporting, data transformation, security, and integration with ODrive.\n",
        "\n",
        "Enhanced Function\n",
        "id: collect_data_enhanced\n",
        "name: Collect Data Enhanced\n",
        "type: code.js\n",
        "content: |-\n",
        "  function collectData() {\n",
        "    try {\n",
        "      // Configuration options from Properties Service\n",
        "      const scriptProperties = PropertiesService.getScriptProperties();\n",
        "      const apiUrl = scriptProperties.getProperty('API_URL');\n",
        "      const apiKey = scriptProperties.getProperty('API_KEY');\n",
        "      const folderId = scriptProperties.getProperty('DRIVE_FOLDER_ID');\n",
        "      const email = scriptProperties.getProperty('NOTIFICATION_EMAIL');\n",
        "\n",
        "      // Validate configuration\n",
        "      if (!apiUrl || !apiKey || !folderId || !email) {\n",
        "        throw new Error('Missing configuration options in Properties Service');\n",
        "      }\n",
        "\n",
        "      // Fetch data from API\n",
        "      const response = UrlFetchApp.fetch(apiUrl, {\n",
        "        headers: { Authorization: `Bearer ${apiKey}` },\n",
        "      });\n",
        "\n",
        "      // Parse the response\n",
        "      const data = JSON.parse(response.getContentText());\n",
        "\n",
        "      // Validate data\n",
        "      if (!data || typeof data !== 'object') {\n",
        "        throw new Error('Invalid data received from API');\n",
        "      }\n",
        "\n",
        "      // Transform data (example: filter and reformat)\n",
        "      const transformedData = data.map(item => ({\n",
        "        id: item.id,\n",
        "        name: item.name,\n",
        "        value: item.value * 1.1, // Example transformation\n",
        "      }));\n",
        "\n",
        "      // Encrypt data for security\n",
        "      const encryptedData = Utilities.base64Encode(JSON.stringify(transformedData));\n",
        "\n",
        "      // Save data to Google Drive\n",
        "      const folder = DriveApp.getFolderById(folderId);\n",
        "      const fileName = `data_${new Date().toISOString().replace(/[:.]/g, '-')}.json`;\n",
        "      const file = folder.createFile(fileName, encryptedData);\n",
        "\n",
        "      // Log success\n",
        "      Logger.log(`Data saved to Google Drive: ${file.getUrl()}`);\n",
        "\n",
        "      // Send success notification\n",
        "      MailApp.sendEmail({\n",
        "        to: email,\n",
        "        subject: 'Data Collection Successful',\n",
        "        body: `Data saved to Google Drive: ${file.getUrl()}`,\n",
        "      });\n",
        "\n",
        "      return file.getUrl();\n",
        "\n",
        "    } catch (error) {\n",
        "      // Log and handle errors\n",
        "      Logger.log(`Error: ${error.message}`);\n",
        "\n",
        "      // Send error notification\n",
        "      MailApp.sendEmail({\n",
        "        to: email,\n",
        "        subject: 'Error in Data Collection Script',\n",
        "        body: `Error message: ${error.message}`,\n",
        "      });\n",
        "\n",
        "      throw error; // Re-throw the error for debugging\n",
        "    }\n",
        "  }\n",
        "\n",
        "\n",
        "Key Enhancements\n",
        "\n",
        "Configuration Options:\n",
        "\n",
        "Uses PropertiesService to store and retrieve configuration values (API_URL, API_KEY, DRIVE_FOLDER_ID, NOTIFICATION_EMAIL).\n",
        "Validates configuration options before proceeding.\n",
        "\n",
        "\n",
        "Error Reporting:\n",
        "\n",
        "Sends email notifications for both success and failure.\n",
        "\n",
        "\n",
        "Data Transformation:\n",
        "\n",
        "Adds an example transformation step to filter and reformat the data.\n",
        "\n",
        "\n",
        "Security:\n",
        "\n",
        "Encrypts the data using Utilities.base64Encode before saving it to Google Drive.\n",
        "\n",
        "\n",
        "ODrive Integration:\n",
        "\n",
        "Ensures the Google Drive folder is synced with ODrive for automatic backup across cloud services.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "How to Use\n",
        "\n",
        "Set Up Properties:\n",
        "\n",
        "In Google Apps Script, go to File > Project Properties > Script Properties.\n",
        "Add the following key-value pairs:\n",
        "\n",
        "API_URL: Your API endpoint.\n",
        "API_KEY: Your API key (if required).\n",
        "DRIVE_FOLDER_ID: The ID of the Google Drive folder.\n",
        "NOTIFICATION_EMAIL: Your email for notifications.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Run the Function:\n",
        "\n",
        "Execute collectData() in the Apps Script editor.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Next Steps\n",
        "\n",
        "ODrive Sync:\n",
        "\n",
        "Ensure the Google Drive folder is synced with ODrive for cross-cloud backup.\n",
        "\n",
        "\n",
        "Advanced Security:\n",
        "\n",
        "For sensitive data, consider using Google Drive's advanced encryption features or third-party encryption tools.\n",
        "\n",
        "\n",
        "Custom Transformations:\n",
        "\n",
        "Modify the transformedData logic to suit your specific data requirements.\n",
        "\n",
        "\n",
        "\n",
        "Let me know if you need further assistance! 🚀"
      ],
      "metadata": {
        "id": "4V7bHHQgbdWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3wz_KIt1bb-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save data to a file\n",
        "data = {\"example\": \"data\"}\n",
        "with open('/content/drive/My Drive/data.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "fPCiCdLHdknM",
        "outputId": "b41d2db6-f442-43d6-e571-52511a63f58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " UrlFetchApp.fetch(/content/myapp/autogen0404.db.)"
      ],
      "metadata": {
        "id": "vqCM974Te4ql",
        "outputId": "8a8ded0b-827d-436f-d363-02a857fc349a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-20-6d568df618c2>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-6d568df618c2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    UrlFetchApp.fetch(/content/myapp/autogen0404.db.)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests google-api-python-client\n",
        "import requests\n",
        "import googleapiclient # this is part of google-api-python-client\n",
        "\n",
        "# Now you can use requests and googleapiclient\n",
        "# Example:\n",
        "response = requests.get(\"https://www.google.com\")\n",
        "print(response.status_code)"
      ],
      "metadata": {
        "id": "lSBGfsqffUyr",
        "outputId": "c37a4fa7-4622-4385-bcd5-d4f55e111dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.160.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save data to Google Drive\n",
        "with open('/content/drive/My Drive/data.json', 'w') as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "print('Data saved to Google Drive!')\n"
      ],
      "metadata": {
        "id": "hNCalksYhvOK",
        "outputId": "340431da-628b-4101-80c8-769f0a92416d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'json' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ae824c0c5caa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save data to Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/data.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data saved to Google Drive!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert JSON data to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Perform analysis\n",
        "df['new_column'] = df['existing_column'] * 1.1\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "biVTL7nMh2nB",
        "outputId": "1b5f28a9-e771-483c-8d85-31bb2502c0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3319bdb825fc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert JSON data to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Perform analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Your existing data\n",
        "data = {\"example\": \"data\"}\n",
        "\n",
        "# Create a DataFrame with an explicit index\n",
        "df = pd.DataFrame([data], index=[0])  # or any suitable index\n",
        "\n",
        "# Now you can perform your analysis\n",
        "df['new_column'] = 0  # Initialize the new column (since 'existing_column' doesn't exist)\n",
        "# If 'existing_column' was intended to be 'example', modify accordingly:\n",
        "# df['new_column'] = df['example'] * 1.1\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "_YCtlsEqiBMC",
        "outputId": "963c1145-2144-4845-e9d9-1c1d7c46bb6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  example  new_column\n",
            "0    data           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: retreve all my ai conversations\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Replace with your actual credentials\n",
        "SERVICE_ACCOUNT_FILE = '/content/drive/My Drive/your_service_account_credentials.json'  # Path to your service account key file\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
        "\n",
        "creds = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "# Call the Drive v3 API\n",
        "results = service.files().list(\n",
        "    pageSize=100, fields=\"nextPageToken, files(id, name)\").execute()\n",
        "items = results.get('files', [])\n",
        "\n",
        "if not items:\n",
        "    print('No files found.')\n",
        "else:\n",
        "    print('Files:')\n",
        "    for item in items:\n",
        "        print(u'{0} ({1})'.format(item['name'], item['id']))\n"
      ],
      "metadata": {
        "id": "Wz1Rd5DjiJs1",
        "outputId": "58ee9831-bcd7-4358-c89e-38f6206349c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/your_service_account_credentials.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-249e5831ce1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mSCOPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.googleapis.com/auth/drive.readonly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m creds = service_account.Credentials.from_service_account_file(\n\u001b[0m\u001b[1;32m     11\u001b[0m     SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/service_account.py\u001b[0m in \u001b[0;36mfrom_service_account_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m         info, signer = _service_account_info.from_filename(\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"client_email\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_uri\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/_service_account_info.py\u001b[0m in \u001b[0;36mfrom_filename\u001b[0;34m(filename, require, use_rsa_signer)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msigner\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/your_service_account_credentials.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-sxCNRD3SFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "W2Ceymyoo6ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U autogenstudio\n",
        "!autogenstudio ui --port 8080 --appdir ./myapp"
      ],
      "metadata": {
        "id": "Vw1XrEFGo9GK",
        "outputId": "d7f1c7eb-9861-4261-b091-92433fc2cff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogenstudio\n",
            "  Downloading autogenstudio-0.4.1.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from autogenstudio) (2.10.6)\n",
            "Collecting pydantic-settings (from autogenstudio)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastapi[standard] (from autogenstudio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from autogenstudio) (0.15.1)\n",
            "Collecting aiofiles (from autogenstudio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting python-dotenv (from autogenstudio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from autogenstudio) (14.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogenstudio) (1.26.4)\n",
            "Collecting sqlmodel (from autogenstudio)\n",
            "  Downloading sqlmodel-0.0.22-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting psycopg (from autogenstudio)\n",
            "  Downloading psycopg-3.2.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting alembic (from autogenstudio)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting loguru (from autogenstudio)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from autogenstudio) (6.0.2)\n",
            "Collecting html2text (from autogenstudio)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting autogen-core<0.5,>=0.4.5 (from autogenstudio)\n",
            "  Downloading autogen_core-0.4.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting autogen-agentchat<0.5,>=0.4.5 (from autogenstudio)\n",
            "  Downloading autogen_agentchat-0.4.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting autogen-ext<0.5,>=0.4.2 (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading autogen_ext-0.4.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting azure-identity (from autogenstudio)\n",
            "  Downloading azure_identity-1.20.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonref~=1.1.0 (from autogen-core<0.5,>=0.4.5->autogenstudio)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting opentelemetry-api>=1.27.0 (from autogen-core<0.5,>=0.4.5->autogenstudio)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core<0.5,>=0.4.5->autogenstudio) (11.1.0)\n",
            "Collecting protobuf~=5.29.3 (from autogen-core<0.5,>=0.4.5->autogenstudio)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core<0.5,>=0.4.5->autogenstudio) (4.12.2)\n",
            "Collecting azure-ai-inference>=1.0.0b7 (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting azure-core (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting markitdown>=0.0.1a2 (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading markitdown-0.0.1a4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting playwright>=1.48.0 (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading playwright-1.50.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai>=1.52.2 in /usr/local/lib/python3.11/dist-packages (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (1.61.1)\n",
            "Collecting tiktoken>=0.8.0 (from autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->autogenstudio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->autogenstudio) (2.27.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from alembic->autogenstudio) (2.0.38)\n",
            "Collecting Mako (from alembic->autogenstudio)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.11/dist-packages (from azure-identity->autogenstudio) (43.0.3)\n",
            "Collecting msal>=1.30.0 (from azure-identity->autogenstudio)\n",
            "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->autogenstudio)\n",
            "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi[standard]->autogenstudio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]->autogenstudio) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]->autogenstudio) (3.1.5)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]->autogenstudio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]->autogenstudio) (2.2.0)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->autogenstudio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->autogenstudio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->autogenstudio) (13.9.4)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-inference>=1.0.0b7->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.5->azure-identity->autogenstudio) (1.17.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]->autogenstudio) (2.7.0)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]->autogenstudio) (3.10)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]->autogenstudio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]->autogenstudio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]->autogenstudio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]->autogenstudio) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.5->fastapi[standard]->autogenstudio) (3.0.2)\n",
            "Collecting azure-ai-documentintelligence (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading azure_ai_documentintelligence-1.0.0-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (4.13.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (3.4.1)\n",
            "Collecting mammoth (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading mammoth-1.9.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting markdownify (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting olefile (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.2.2)\n",
            "Collecting pathvalidate (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pdfminer-six (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting puremagic (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pydub (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-pptx (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting speechrecognition (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.0.1)\n",
            "Collecting youtube-transcript-api (from markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->autogenstudio) (2.10.1)\n",
            "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity->autogenstudio)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (4.67.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->autogen-core<0.5,>=0.4.5->autogenstudio) (1.2.18)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.27.0->autogen-core<0.5,>=0.4.5->autogenstudio)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pyee<13,>=12 (from playwright>=1.48.0->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.48.0->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (3.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->autogenstudio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->autogenstudio) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2024.11.6)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]->autogenstudio)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->autogenstudio) (2.22)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core<0.5,>=0.4.5->autogenstudio) (1.17.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core<0.5,>=0.4.5->autogenstudio) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->autogenstudio) (0.1.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.6)\n",
            "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (2025.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (5.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api->markitdown>=0.0.1a2->autogen-ext[azure,magentic-one,openai]<0.5,>=0.4.2->autogenstudio) (0.7.1)\n",
            "Downloading autogenstudio-0.4.1.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_agentchat-0.4.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_core-0.4.7-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogen_ext-0.4.7-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_identity-1.20.0-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg-3.2.4-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading sqlmodel-0.0.22-py3-none-any.whl (28 kB)\n",
            "Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading markitdown-0.0.1a4-py3-none-any.whl (21 kB)\n",
            "Downloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading playwright-1.50.0-py3-none-manylinux1_x86_64.whl (45.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_ai_documentintelligence-1.0.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mammoth-1.9.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
            "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=6c404dd47afb4a545ddd45bcb0f010a3d76d457aa7edb34c2c2f1652b905d812\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/58/7c/d9c8c4d924a1ac2b621add1b2c1d30b639629a33cfdfde6a45\n",
            "Successfully built html2text\n",
            "Installing collected packages: pydub, puremagic, XlsxWriter, uvloop, uvicorn, speechrecognition, python-multipart, python-dotenv, pyee, psycopg, protobuf, portalocker, pathvalidate, olefile, Mako, loguru, jsonref, isodate, importlib-metadata, httptools, html2text, cobble, aiofiles, youtube-transcript-api, watchfiles, tiktoken, starlette, python-pptx, playwright, opentelemetry-api, markdownify, mammoth, azure-core, alembic, sqlmodel, rich-toolkit, pydantic-settings, pdfminer-six, fastapi, azure-ai-inference, azure-ai-documentintelligence, autogen-core, msal, fastapi-cli, autogen-ext, autogen-agentchat, msal-extensions, azure-identity, markitdown, autogenstudio\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-sdk 1.16.0 requires opentelemetry-api==1.16.0, but you have opentelemetry-api 1.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.9 XlsxWriter-3.2.2 aiofiles-24.1.0 alembic-1.14.1 autogen-agentchat-0.4.7 autogen-core-0.4.7 autogen-ext-0.4.7 autogenstudio-0.4.1.1 azure-ai-documentintelligence-1.0.0 azure-ai-inference-1.0.0b9 azure-core-1.32.0 azure-identity-1.20.0 cobble-0.1.4 fastapi-0.115.8 fastapi-cli-0.0.7 html2text-2024.2.26 httptools-0.6.4 importlib-metadata-8.5.0 isodate-0.7.2 jsonref-1.1.0 loguru-0.7.3 mammoth-1.9.0 markdownify-0.14.1 markitdown-0.0.1a4 msal-1.31.1 msal-extensions-1.2.0 olefile-0.47 opentelemetry-api-1.30.0 pathvalidate-3.2.3 pdfminer-six-20240706 playwright-1.50.0 portalocker-2.10.1 protobuf-5.29.3 psycopg-3.2.4 puremagic-1.28 pydantic-settings-2.7.1 pydub-0.25.1 pyee-12.1.1 python-dotenv-1.0.1 python-multipart-0.0.20 python-pptx-1.0.2 rich-toolkit-0.13.2 speechrecognition-3.14.1 sqlmodel-0.0.22 starlette-0.45.3 tiktoken-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 youtube-transcript-api-0.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "047ebb10d0334602aafe1b51612beb6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Loading environment from '/root/.autogenstudio/temp_env_vars.env'\n",
            "\u001b[32m2025-02-17 16:01:25.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.web.initialization\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mInitializing application data folder: myapp \u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m13089\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32m2025-02-17 16:01:25.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.database.db_manager\u001b[0m:\u001b[36minitialize_database\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mCreating database tables...\u001b[0m\n",
            "\u001b[32m2025-02-17 16:01:25.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.database.schema_manager\u001b[0m:\u001b[36m_initialize_alembic\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1mAlembic initialization complete\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "\u001b[32m2025-02-17 16:01:25.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.web.app\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mApplication startup complete. Navigate to http://127.0.0.1:8080\u001b[0m\n",
            "\u001b[32m2025-02-17 16:01:25.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.web.app\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mCleaning up application resources...\u001b[0m\n",
            "\u001b[32m2025-02-17 16:01:25.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.database.db_manager\u001b[0m:\u001b[36mclose\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mClosing database connections...\u001b[0m\n",
            "\u001b[32m2025-02-17 16:01:25.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.database.db_manager\u001b[0m:\u001b[36mclose\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mDatabase connections closed successfully\u001b[0m\n",
            "\u001b[32m2025-02-17 16:01:25.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautogenstudio.web.app\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mApplication shutdown complete\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlmodel import SQLModel\n",
        "from logging.config import fileConfig\n",
        "\n",
        "from sqlalchemy import engine_from_config\n",
        "from sqlalchemy import pool\n",
        "\n",
        "from alembic import context\n",
        "\n",
        "# this is the Alembic Config object, which provides\n",
        "# access to the values within the .ini file in use.\n",
        "config = context.config\n",
        "\n",
        "# Interpret the config file for Python logging.\n",
        "# This line sets up loggers basically.\n",
        "if config.config_file_name is not None:\n",
        "    fileConfig(config.config_file_name)\n",
        "\n",
        "# add your model's MetaData object here\n",
        "# for 'autogenerate' support\n",
        "# from myapp import mymodel\n",
        "# target_metadata = mymodel.Base.metadata\n",
        "target_metadata = SQLModel.metadata\n",
        "\n",
        "# other values from the config, defined by the needs of env.py,\n",
        "# can be acquired:\n",
        "# my_important_option = config.get_main_option(\"my_important_option\")\n",
        "# ... etc.\n",
        "\n",
        "\n",
        "def run_migrations_offline() -> None:\n",
        "    \"\"\"Run migrations in 'offline' mode.\n",
        "\n",
        "    This configures the context with just a URL\n",
        "    and not an Engine, though an Engine is acceptable\n",
        "    here as well.  By skipping the Engine creation\n",
        "    we don't even need a DBAPI to be available.\n",
        "\n",
        "    Calls to context.execute() here emit the given string to the\n",
        "    script output.\n",
        "\n",
        "    \"\"\"\n",
        "    url = config.get_main_option(\"sqlalchemy.url\")\n",
        "    context.configure(\n",
        "        url=url,\n",
        "        target_metadata=target_metadata,\n",
        "        literal_binds=True,\n",
        "        dialect_opts={\"paramstyle\": \"named\"},\n",
        "    )\n",
        "\n",
        "    with context.begin_transaction():\n",
        "        context.run_migrations()\n",
        "\n",
        "\n",
        "def run_migrations_online() -> None:\n",
        "    \"\"\"Run migrations in 'online' mode.\n",
        "\n",
        "    In this scenario we need to create an Engine\n",
        "    and associate a connection with the context.\n",
        "\n",
        "    \"\"\"\n",
        "    connectable = engine_from_config(\n",
        "        config.get_section(config.config_ini_section, {}),\n",
        "        prefix=\"sqlalchemy.\",\n",
        "        poolclass=pool.NullPool,\n",
        "    )\n",
        "\n",
        "    with connectable.connect() as connection:\n",
        "        context.configure(\n",
        "            connection=connection, target_metadata=target_metadata\n",
        "        )\n",
        "\n",
        "        with context.begin_transaction():\n",
        "            context.run_migrations()\n",
        "\n",
        "\n",
        "if context.is_offline_mode():\n",
        "    run_migrations_offline()\n",
        "else:\n",
        "    run_migrations_online()\n"
      ],
      "metadata": {
        "id": "rggKrbvGwUyU",
        "outputId": "05a23e86-ad06-4582-fd0e-41e33a45ca40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'alembic.context' has no attribute 'config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5928528ae250>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# this is the Alembic Config object, which provides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# access to the values within the .ini file in use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Interpret the config file for Python logging.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'alembic.context' has no attribute 'config'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jUIaAogSwq17",
        "outputId": "d24f5bb7-a1da-4325-cc66-7506c0354bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "OneVR-22yFy-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('/content/myapp/autogen0404.db')"
      ],
      "metadata": {
        "id": "1EzvQFD6ybRS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CREATE TABLE alembic_version (\n",
        "\tversion_num VARCHAR(32) NOT NULL,\n",
        "\tCONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)"
      ],
      "metadata": {
        "id": "rnzk_mXay1uA",
        "outputId": "106ea16e-5bc3-4f5c-b349-4c677c4aacd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'(' was never closed (<ipython-input-19-42be6df9ce04>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-42be6df9ce04>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    CREATE TABLE alembic_version (\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for table in tables:\n",
        "    print(table[0])"
      ],
      "metadata": {
        "id": "3OdvLdZs2krc",
        "outputId": "4830db13-8c90-4863-b50c-dcf4a26a27a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tables' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2ea4290a31ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tablealembic_versionalembic_version\tCREATE TABLE alembic_version (\n",
        "\tversion_num VARCHAR(32) NOT NULL,\n",
        "\tCONSTRAINT alembic_version_pkc PRIMARY KEY (version_num)\n",
        ")=\t\u0006\u0017Q+\u0001"
      ],
      "metadata": {
        "id": "-N3LqMpJzaq3"
      }
    }
  ]
}